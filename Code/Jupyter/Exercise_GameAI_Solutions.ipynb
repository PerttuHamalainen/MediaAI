{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_GameAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: General Game-Playing via Deep Reinforcement Learning\n",
        "\n",
        "**Author**: Christian Guckelsberger (Aalto University; Queen Mary, University of London).\n",
        "\n",
        "**Overview**: The focus of this exercise is to apply Deep Reinforcement Learning for general game-playing in a simple gridworld game. \n",
        "\n",
        "You learn the basics of using:\n",
        "- The OpenAI Gym interface ([link](https://gym.openai.com/)). OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms and the de facto playground for reinforcement learning research. \n",
        "- The Gym-MiniGrid environment ([link](https://github.com/maximecb/gym-minigrid)), a game-like environment to be run within Gym. It is particularly simple, lightweight and fast. Gridworld environments are commonly used to test new algorithms for controlling artificial agents, e.g. a player avatar.\n",
        "- State-of-the-art Reinforcement Learning algorithms from Stable Baselines 3 ([link](https://stable-baselines3.readthedocs.io/en/master/)). Stable Baselines 3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch.\n",
        "\n",
        "The notebook reuses code from Chanseok Kang / goodboychan ([source](https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb)) and Stable Baselines 3 ([source](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb#scrollTo=U29X1-B-AIKE))."
      ],
      "metadata": {
        "id": "xjlLiuhuTR3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies\n",
        "While OpenAI Gym comes by default with Colab, the MiniGrid package and Stable Baselines 3 must be installed explicitly."
      ],
      "metadata": {
        "id": "4WEQDgs05dHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install gym_minigrid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpon7IIf5e-E",
        "outputId": "35f311c5-7e26-4816-f651-b1e26cc8a5e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-3).\n",
            "freeglut3-dev set to manually installed.\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms keyboard-configuration libargon2-0\n",
            "  libcap2 libcryptsetup12 libdevmapper1.02.1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxi-dev\n",
            "  libxmu-dev libxmu-headers libxnvctrl0 libxtst6 nsight-compute-2020.2.1\n",
            "  nsight-compute-2022.1.0 nsight-systems-2020.3.2 nsight-systems-2020.3.4\n",
            "  nsight-systems-2021.5.2 nvidia-dkms-510 nvidia-kernel-common-510\n",
            "  nvidia-kernel-source-510 nvidia-modprobe nvidia-settings openjdk-11-jre\n",
            "  policykit-1 policykit-1-gnome python3-xkit screen-resolution-extra systemd\n",
            "  systemd-sysv udev xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.10 [784 kB]\n",
            "Fetched 784 kB in 2s (353 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.4.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.10.0+cu111)\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.17.3)\n",
            "Collecting atari-py==0.2.6\n",
            "  Downloading atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.7.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py==0.2.6->stable-baselines3[extra]) (1.15.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3[extra]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3[extra]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3[extra]) (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.43.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2018.9)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/8f/ba/1d22e9d2f332f07aaa57041f5dd569c2cb40a92bd6374a0b743ec3dfae97/atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl#sha256=d9e2c25d39783867c2f29d1dd9d3a659fc56036456d07dc9efe8bd7bb31a07d7 (from https://pypi.org/simple/atari-py/))\n",
            "Reason for being yanked: re-release with new wheels\u001b[0m\n",
            "Installing collected packages: stable-baselines3, atari-py\n",
            "  Attempting uninstall: atari-py\n",
            "    Found existing installation: atari-py 0.2.9\n",
            "    Uninstalling atari-py-0.2.9:\n",
            "      Successfully uninstalled atari-py-0.2.9\n",
            "Successfully installed atari-py-0.2.6 stable-baselines3-1.4.0\n",
            "Collecting gym_minigrid\n",
            "  Downloading gym_minigrid-1.0.3-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from gym_minigrid) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from gym_minigrid) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.9.6->gym_minigrid) (0.16.0)\n",
            "Installing collected packages: gym-minigrid\n",
            "Successfully installed gym-minigrid-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Basic Notebook Settings\n",
        "These settings work for most parts of this exercise. You may benefit from adjusting `figure.figsize` for some modifications of the gridworld."
      ],
      "metadata": {
        "id": "R28R6-5lTTF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 10) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "5AIkz8vETXBo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "The functions below allow to render a gameplay sequence in the gridworld as a video to be shown in the notebook."
      ],
      "metadata": {
        "id": "FKfzeICSgjgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import glob\n",
        "import io\n",
        "from IPython.display import HTML\n",
        "from IPython import display \n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
        "def MonitorWrapper(env):\n",
        "    env = Monitor(env, './video', force=True)\n",
        "    return env\n",
        "\n",
        "# Show a video which was previously created through e.g. gym Monitor\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        print(\"Playing video\", mp4)\n",
        "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")"
      ],
      "metadata": {
        "id": "Q9yZbzSCgidN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gridworld\n",
        "A gridworld is an abstract, 2d, tile-based virtual environment that is very popular in reinforcement learning research, as it affords high introspection and performance. Here, we use the **MiniGrid** Minimalistic Gridworld Environment ([link](https://github.com/maximecb/gym-minigrid)). This environment implements the **OpenAI Gym** ([https://gym.openai.com/](link)) interfaces and can thus be combined with many other state-of-the-art control algorithms.\n",
        "\n",
        "<img src=\"https://i.ibb.co/kBzkC2P/minigrid6x6.png\" width=\"200\"/>\n",
        "\n",
        "For best performance, we use one of the smallest and simplest available environments, the `MiniGrid-Empty-Random-6x6-v0`. It's a 6x6 empty room surrounded by impenetrable walls (dark grey) tiles and the player (red) position is randomly initialised in every episode. The player's goal is to reach the goal square (green). \n",
        "\n",
        "**Exercise 1 (explore environments)**: Load different MiniGrid environments and visualise them by executing the code in the two cells below. Check out the MiniGrid documentation for all available environments. Reset to the original code once done.\n",
        "\n",
        "_Note_: Code comments in the form `# EXERCISE <NO>` highlight where code changes are required to complete an exercise.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QY8pH6BGTXmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym_minigrid\n",
        "from gym_minigrid.wrappers import FlatObsWrapper, FullyObsWrapper, ImgObsWrapper, RGBImgObsWrapper\n",
        "\n",
        "env = ImgObsWrapper(FullyObsWrapper(gym.make('MiniGrid-Empty-Random-6x6-v0'))) # EXERCISE 1, EXERCISE 2, EXERCISE 5\n",
        "# env = ImgObsWrapper(FullyObsWrapper(gym.make('MiniGrid-UnlockPickup-v0'))) # Solution example for EXERCISE 1\n",
        "# env = ImgObsWrapper(gym.make('MiniGrid-Empty-Random-6x6-v0')) # Solution for EXERCISE 2 (partial observation)\n",
        "# env = ImgObsWrapper(RGBImgObsWrapper(gym.make('MiniGrid-Empty-Random-6x6-v0'))) # Solution for EXERCISE 2/EXERCISE 5 (RGB raw pixel observation)\n",
        "\n",
        "# Print available actions in environment\n",
        "# env.action_space.n provides the total number of all actions in the environment\n",
        "print(\"Available actions in environment:\")\n",
        "for action_index in range(0, env.action_space.n):\n",
        "   print(action_index,\":\",env.actions(action_index))\n",
        "\n",
        "# Reduce action space\n",
        "# env.action_space = spaces.Discrete(3) # Solution for EXERCISE 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSRiqADdreYK",
        "outputId": "578e1f85-52d6-4614-9ed4-b1d28879d877"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available actions in environment:\n",
            "0 : Actions.left\n",
            "1 : Actions.right\n",
            "2 : Actions.forward\n",
            "3 : Actions.pickup\n",
            "4 : Actions.drop\n",
            "5 : Actions.toggle\n",
            "6 : Actions.done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interacting with the Gridworld\n",
        "\n",
        "Any one specific gridworld environment implements a Markov Decision Process (MDP, [Wikipedia]((Wikipedia)[https://en.wikipedia.org/wiki/Markov_decision_process])), i.e. it represents a sequential decision-making problem. The code below represents one full interaction cycle with the environemnt.\n",
        "\n",
        "<img src=\"https://gcdnb.pbrd.co/images/iJ7oTFXyj7gB.png?o=1\" width=\"500\"/>\n",
        "\n",
        "As the player takes an action, the world will be changed and return an observation, a reward, and a \"done\" flag (not in picture).\n",
        "- **Observation**: How the world looks like at this moment, top-down. A 3-dimensional matrix in the shape of the environment specifying 3 values per square denoting its RGB color. The size for the 6x6 grid is this 6x6x3.\n",
        "- **Reward**: The player receives a positive reward when reaching the goal. A small negative reward is substracted from this final goal reward for each step required along the way. A scalar value, here 0 everywhere but in green square.\n",
        "- **Done**: Indicating whether the goal (green square) has been reached.  Boolean, False everywhere but in green square.\n",
        "\n",
        "_Note:_ you can ignore the grey highlighted area below. It indicates what the player would see if we assumed that they can only observe a part of the environment in their viewing direction (\"_partial observability_\"). For this exercise however, we assume _full observability_.\n",
        "\n",
        "**Exercise 2 (changing observation type)**: Experiment with the MiniGrid environment wrappers to change the type of observation returned. Consult the MiniGrid documentation for information on what the various wrappers do. Can you produce a _partial observation_? Can you produce a _RGB raw pixel observation_? Reset to the original code once done."
      ],
      "metadata": {
        "id": "svuk1JoGZoie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "before_img = env.render('rgb_array') # render the gridworld before an action is taken\n",
        "action = env.actions.forward # select \"move forward\" action\n",
        "obs, reward, done, _ = env.step(action) # perform action on the gridlworld, thus modifying it\n",
        "after_img = env.render('rgb_array') # render the gridworld again after the action was taken\n",
        "plt.imshow(np.concatenate([before_img, after_img], 1)); # compare \"before\" and \"after\" renderings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "HjYfbkYTTYZi",
        "outputId": "2b6e696b-2cd2-4782-9b33-9d0dbb00f6fa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the data returned from the environment\n",
        "print(\"Observation:\", obs)\n",
        "print(obs.shape)\n",
        "print(\"Reward:\", reward)\n",
        "print(\"Done:\", done)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzOfNYr6cB3C",
        "outputId": "7d5bcda0-edbb-429c-a198-0976b42a8db0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation: [[[ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [10  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 1  0  0]\n",
            "  [ 8  1  0]\n",
            "  [ 2  5  0]]\n",
            "\n",
            " [[ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]\n",
            "  [ 2  5  0]]]\n",
            "(8, 8, 3)\n",
            "Reward: 0\n",
            "Done: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reinforcement Learning\n",
        "\n",
        "The goal of Reinforcement Learning is to find an optimal policy for the given MDP. In other words, we want to find a decision-rule that provides us with maximum reward in our gridworld environment. \n",
        "\n",
        "From Stable Baslines 3 we use:\n",
        "- **Proximal Policy Optimisation (PPO)**: a state-of-the-art Reinforcement Learning algorithm to learn the policy ([docs](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html)). As an Actor-Critic method, it uses a value function to improve the policy gradient descent (by reducing the variance). It is an on-policy algorithm, which means that the trajectories used to update the networks must be collected using the latest policy. It is usually less sample efficient than off-policy alorithms like DQN, SAC or TD3, but is much faster regarding wall-clock time.\n",
        "- **Multilayer Perceptron (MlpPolicy)**: a neural network function approximator for the policy with 2 layers of 64 nodes each. This typically works best with small symbolic inputs, rather than raw pixel data. Deep learning extends this network to capture more complex policies.\n",
        "\n",
        "\n",
        "### Random Policy\n",
        "\n",
        "As a benchmark for our experiment, we evaluate the performance of a player driven by a random policy through visualisation in a video and statistics. To this end, we initialise a policy but do not train it.\n",
        "\n",
        "**Exercise 3 (initialise policy):** Initialise a MlpPolicy to be trained with PPO. Check out the PPO documentation ([link](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)) for an example.\n",
        "\n",
        "_Note_: The cell below contains some extra code for recording a video of the gameplay resulting from sampling from the random policy. To record a video, Stable Baselines 3 requires us to wrap the environment into a vectorised environment `DummyVecEnv` which can be used for multiprocess training. This is why the sampled actions, and the return values from the environment are wrapped into arrays.\n",
        "\n"
      ],
      "metadata": {
        "id": "fpuSiVu9YedP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "! rm -rf \"video\"\n",
        "\n",
        "# Imports\n",
        "import stable_baselines3\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "# Define how many steps to take / how much video to record\n",
        "n_steps = 50\n",
        "\n",
        "# Untrained, i.e. random policy\n",
        "rnd_policy = None # EXERCISE 3\n",
        "#rnd_policy = PPO(\"MlpPolicy\", env, verbose=1) # Solution for EXERCISE 3\n",
        "\n",
        "# Wrap the environment for video recording - not changing the original environment\n",
        "env_vec = DummyVecEnv([lambda: env])\n",
        "env_rec = VecVideoRecorder(env_vec, video_folder='video', record_video_trigger=lambda step: step == 0, video_length=n_steps, name_prefix='')\n",
        "\n",
        "# Perform <video_length> many steps in the environment\n",
        "# Thanks to the VecVideoRecorder wrapper, these steps will be automatically recorded\n",
        "obs = env_rec.reset()\n",
        "done = False\n",
        "action_log = []\n",
        "for _ in range(n_steps):\n",
        "  action, _ = rnd_policy.predict(obs) # Sample next action to perform from policy\n",
        "  action_log.append((action,env.actions(action).name)) # Record actions\n",
        "  obs, _, done, _ = env_rec.step(action) # Take a step\n",
        "\n",
        "env.close()\n",
        "\n",
        "print(\"Reached goal: \", done)\n",
        "print(\"Actions performed: \", action_log)\n",
        "\n",
        "# Close the video recorder\n",
        "env_rec.close()\n",
        "show_video()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "Dpor--9OifW0",
        "outputId": "f55aceb6-a87c-4193-f3a1-8da78ab4ee9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Saving video to /content/video/-step-0-to-step-50.mp4\n",
            "Reached goal:  [False]\n",
            "Actions performed:  [(array([6]), 'done'), (array([1]), 'right'), (array([1]), 'right'), (array([2]), 'forward'), (array([2]), 'forward'), (array([3]), 'pickup'), (array([0]), 'left'), (array([4]), 'drop'), (array([2]), 'forward'), (array([6]), 'done'), (array([2]), 'forward'), (array([4]), 'drop'), (array([3]), 'pickup'), (array([4]), 'drop'), (array([0]), 'left'), (array([6]), 'done'), (array([3]), 'pickup'), (array([2]), 'forward'), (array([6]), 'done'), (array([2]), 'forward'), (array([0]), 'left'), (array([6]), 'done'), (array([3]), 'pickup'), (array([0]), 'left'), (array([0]), 'left'), (array([0]), 'left'), (array([5]), 'toggle'), (array([1]), 'right'), (array([2]), 'forward'), (array([5]), 'toggle'), (array([1]), 'right'), (array([6]), 'done'), (array([5]), 'toggle'), (array([2]), 'forward'), (array([1]), 'right'), (array([1]), 'right'), (array([1]), 'right'), (array([3]), 'pickup'), (array([1]), 'right'), (array([5]), 'toggle'), (array([5]), 'toggle'), (array([3]), 'pickup'), (array([5]), 'toggle'), (array([5]), 'toggle'), (array([5]), 'toggle'), (array([6]), 'done'), (array([1]), 'right'), (array([5]), 'toggle'), (array([1]), 'right'), (array([1]), 'right')]\n",
            "Playing video video/-step-0-to-step-50.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `evaluate_policy` function from Stable Baselines 3 to conveniently evaluate a policy on an environment. A mean reward of 0 means that the player has never reached the goal. Reaching a mean reward of 1 would indicate that the player has reached the goal state in every episode. However, this is very unlikely as a small negative reward will be substracted for every step they require to reach the goal tile.\n",
        "\n",
        "**Exercise 4 (prune action space):**\n",
        "- Take a note of the present performance statistics. \n",
        "- Identify uncessary actions in the actions log above (\"Actions performed:\")\n",
        "- Determine which of the performed actions have no effect in the chosen environment by consulting the MiniGrid [documentation](https://github.com/maximecb/gym-minigrid).\n",
        "- Reduce the action space given to the policy to those actions that actually have an effect in the chosen environment. To this end, you have to replace `n` in the corresponding code line. The environment will make use of the first n actions as printed earlier (\"Available actions in environment:\").\n",
        "- Repeat the experiment, see how the change has affected the statistics. \n"
      ],
      "metadata": {
        "id": "NgpR6jSHif30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Run the policy for 100 episodes\n",
        "# In each episode, the player has a maximum of (4*size*size) steps to reach the goal\n",
        "# I.e. in 5x5 environment, that's 100 steps to get there\n",
        "mean_reward, std_reward = evaluate_policy(rnd_policy, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.4f} +/- {std_reward:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgqNH0wjZChi",
        "outputId": "927ad2e0-6835-4323-fad2-f811d75f0e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:0.0000 +/- 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learned Policy\n",
        "\n",
        "Stable Baselines 3 conveniently packages the policy learning into a single function. We train the policy for 10000 timesteps.\n",
        "\n",
        "**Exercise 5 (CNN Policy on raw pixel data)**:\n",
        "The present performance is not great, as the MlpPolicy cannot capture well spatial relationships in the grid, and is not invariant to e.g. rotation. Thus:\n",
        "- Take a note of the present performance statistics.\n",
        "- Switch the policy to `CnnPolicy`. Based on a Convolutional Neural Network (CNN), the policy can better capture spatial relationships in the 2D gridworld observation.\n",
        "- For small environments, the default observation is too small to serve as input to the CnnPolicy. Therefore, switch the observation to raw RGB pixel data. You have learned how to choose an appropriate wrapper in Exercise 2.\n",
        "- Repeat the experiment, see how the change has affected the statistics. \n"
      ],
      "metadata": {
        "id": "4aVCtMHuhjoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the policy\n",
        "env = ImgObsWrapper(RGBImgObsWrapper(FullyObsWrapper(gym.make('MiniGrid-Empty-Random-6x6-v0'))))\n",
        "trained_policy = None # EXERCISE 3, EXERCISE 5\n",
        "#trained_policy = PPO(\"MlpPolicy\", env, verbose=1) # Solution for EXERCISE 3\n",
        "#trained_policy = PPO('CnnPolicy', env, verbose=0) # Solution for EXERCISE 5\n",
        "trained_policy.learn(total_timesteps=10000)\n",
        "\n",
        "# Wrap the environment for the video recording - not changing the original environment\n",
        "env_vec = DummyVecEnv([lambda: env])\n",
        "env_rec = VecVideoRecorder(env_vec, video_folder='video', record_video_trigger=lambda step: step == 0, video_length=50, name_prefix='')\n",
        "\n",
        "# Perform <video_length> many steps in the environment\n",
        "# Thanks to the VecVideoRecorder wrapper, these steps will be automatically recorded\n",
        "obs = env_rec.reset()\n",
        "for _ in range(env_rec.video_length):\n",
        "  action, _ = trained_policy.predict(obs)\n",
        "  obs, _, _, _ = env_rec.step(action)\n",
        "\n",
        "# Close the video recorder\n",
        "env_rec.close()\n",
        "show_video()\n",
        "\n",
        "# Evaluate policy\n",
        "mean_reward, std_reward = evaluate_policy(trained_policy, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.4f} +/- {std_reward:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lm4B7HJRhmKx",
        "outputId": "f527ff47-01ca-4688-8bd1-c4358c7c23e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 0.216    |\n",
            "| time/              |          |\n",
            "|    fps             | 284      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 107         |\n",
            "|    ep_rew_mean          | 0.278       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 180         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014190456 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | -0.113      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0179     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    value_loss           | 0.00838     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 102         |\n",
            "|    ep_rew_mean          | 0.313       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 167         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 36          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021549288 |\n",
            "|    clip_fraction        | 0.223       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.92       |\n",
            "|    explained_variance   | 0.12        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0493     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    value_loss           | 0.00874     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 81.5        |\n",
            "|    ep_rew_mean          | 0.457       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 161         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024326103 |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | 0.219       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.059      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0363     |\n",
            "|    value_loss           | 0.0106      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 36.8       |\n",
            "|    ep_rew_mean          | 0.766      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 157        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 64         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03178557 |\n",
            "|    clip_fraction        | 0.358      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.83      |\n",
            "|    explained_variance   | 0.307      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.025     |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0459    |\n",
            "|    value_loss           | 0.0228     |\n",
            "----------------------------------------\n",
            "Saving video to /content/video/-step-0-to-step-50.mp4\n",
            "Playing video video/-step-0-to-step-50.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:0.5661 +/- 0.4817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Where to go from here?\n",
        "\n",
        "**Well done** on completing the notebook! :-)\n",
        "\n",
        "**Further things** you can try: \n",
        "\n",
        "- Train a policy on more complex MiniGrid environments. \n",
        "- Observe the effect of training a policy on environments without random initialisation. \n",
        "- Experiment with the PPO parameters or use a different learning algorithm altogether, e.g. Soft Actor Critic.\n",
        "- Transfer learning: try a trained policy on other MiniGrid environments of a similar kind.\n",
        "- Curriculum learning: start with a smaller environment, then update policy on larger environment.\n",
        "- Explore Stable Baseline 3's extended evaluation facilities, e.g. to plot policy loss curves.\n",
        " "
      ],
      "metadata": {
        "id": "hqoNCQgdaMxT"
      }
    }
  ]
}